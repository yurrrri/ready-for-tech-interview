## 운영체제

### process를 간단히 설명해 주세요.
    
- 프로세스란, 실행파일로 존재하던 프로그램이 실행되기위해 메모리에 적재되어 CPU에 의해 실행되는 단위를 말합니다.
    
#### 프로그램, 프로세스, 스레드의 차이에 대해 설명해주세요.

- 프로그램은 하드디스크에 저장되어있는 실행파일을 의미하며, 프로세스는 메모리에 적재되어 현재 CPU에 의해 할당받아 실행되고 있는 프로그램을 의미합니다.
- 스레드는 한 프로세스 내에서 실행되는 동작의 단위를 의미합니다.

#### 프로그램이 컴파일 되어 실행되는 과정을 간략하게 설명해주세요.

- 프로그램이 실행되기 위해 메모리 영역에 올라갈 때, 컴퓨터가 처리할 수 있는 기계어로 컴파일되어 메모리에 올라가게 되며, 메모리에 올라가는 프로세스는 CPU에 의해 할당받아 실행됩니다.

### ⭐ process의 memory의 영역에 대해서 설명해 주세요.

- 프로세스의 메모리 구역은 코드, 데이터, 힙, 스택 영역으로 이루어져있으며, 프로세스마다 **각각 독립적으로 할당받습니다.**
- 코드 영역은 코드가 저장되는 메모리 영역이며, 데이터 영역은 전역 변수와 static 변수가 저장되는 메모리 영역입니다. 스택 영역은 함수 호출된 뒤 복귀할 주소 및 데이터를 임시적으로 저장하기 위해 사용하는 공간입니다. 마지막으로 힙 영역은 프로그래머가 직접 해당 영역을 동적 할당하거나 해제하는 메모리 영역입니다.
    
#### 초기화 하지 않은 변수들은 어디에 저장될까요?

- Block Stated Symbol 영역에 저장됩니다.
    
#### 일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?
    
- stack은 프로세스 마다 처음 실행될 때 컴파일 단계에서 고정된 크기로 할당되며, heap은 프로그래머가 필요에 의해 런타임 단계에서 동적할당하는 영역이므로 크기가 항상 매우 크다고 말하기는 어려움
    
#### Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?
    
- 스택 영역 안에서 호출된 변수(값 타입)들은 실행이 모두 끝났을 때 메모리에서 사라지므로, stack 영역의 접근 속도가 더 빠릅니다.
    
#### 다음과 같이 공간을 분할하는 이유가 있을까요?
    
- 각 영역의 역할이 모두 다르기 때문에 데이터의 종류에 따라 속도를 더 빠르게하고 최적의 조건으로 사용하기 위해 메모리 구조를 효율적으로 설계하기 위해서 분할했다고 생각합니다.
    
### ⭐⭐⭐⭐ Multi process에 대해서 설명해 주세요.
    
- 멀티프로세스란, 2개 이상의 프로세스가 동시에 실행되는 것을 의미합니다. “동시에 실행한다” 라는 개념에는 동시성과 병렬성 두 가지 의미가 있습니다.
- 동시성은 1개 이상의 cpu core에서 여러 프로세스를 짧은 시간동안 번갈아가면서 연산을 하게 되는 시분할 시스템으로 실행되는 것을 의미하며, 병렬성은 여러 cpu core에서 여러 프로세스가 동시에 실행되는 것을 의미합니다.
    
#### process의 context는 무엇인가요?
    
- context란 프로세스들이 어떤 상태로 수행되고 있는지에 대한 총체적인 정보이며, PCB에 저장하게 됩니다. 시분할 시스템에서는 CPU가 매우 빠른속도로 process를 번갈아가면서 실행하기 때문에 이전 프로세스에서 어떤 명령어까지 수행했는지, register에는 어떤 값이 저장되어있는지 등에 대한 정보가 필요합니다. 이러한 프로세스의 현재 수행 상황에 대한 전반적인 정보를 context라고 합니다.

#### Context switch에 대해서 설명해 주세요.
    
- 시분할 시스템에서 한 프로세스에서 다른 프로세스로 CPU 제어권을 넘겨주는 것을 의미합니다. 이 때, 이전의 프로세스 state를 PCB에 저장하여 보관하고 있다가 다시 새로운 프로세스를 실행할 때 보관된 state를 복구하는 작업이 이루어집니다.
    
- Q. PCB(Process Control Block)에 저장되는 것들은 무엇이 있나요?
    
    PCB는 운영체제가 프로세스를 관리하기 위해 만든 자료구조로서, 각 프로세스마다 독립적으로 가지고 있습니다. 그리고 다음과 같은 정보가 포함되어있습니다.
    
    - 프로세스의 상태값
    - 실행중이던 코드의 메모리 주소값
    - 레지스터의 값
    
- Q. process의 state에는 어떤 것들이 있나요?
    
    프로세스는 **실행, 준비, 봉쇄** 3가지의 상태로 구분됩니다.
    
    준비는 프로세스가 메모리에 적재되어있는 상황에서 CPU만 할당받으면 바로 명령을 수행할 수 있는 상태이고, 실행은 프로세스가 CPU를 점유하여 명령을 수행중인 상태, 봉쇄는 CPU를 할당받아도 명령을 실행할 수 없는 상태로서, 대표적으로는 프로세스가 입출력 작업이 진행중인 경우가 있습니다.
    
### ⭐⭐ Multi thread에 대해서 설명해 주세요.
    
- 멀티스레드는 하나의 프로세스 내에서 두 개 이상의 스레드를 생성하여 동시에 여러 작업을 수행할 수 있도록 하는 기술입니다
- 스레드는 한 프로세스 내에서 실행되는 기능의 단위 하나하나를 의미하는 것으로, 스레드 각각은 독립적으로 스택 메모리를 할당받아 실행되며 나머지 코드, 데이터, 힙 영역은 다른 스레드와 공유하게 됩니다.
    
#### thread는 왜 독립적인 stack memory영역이 필요한가요?
    
- thread의 stack memory영역에는 함수 호출에 필요한 인자나 지역변수 등이 저장되어있는 영역으로, 스레드가 프로세스 내에서 독립적인 기능을 실행한다는 것은 독립적으로 함수를 실행한다는 의미와 같으므로, 스레드가 각 독립적인 기능을 실행하기 위해서는 독립적인 메모리 영역이 필요합니다.
    
#### process와 thread를 비교설명 해주세요.

- 프로세스는 실행 프로그램이 메모리에 적재되어 실행되는 하나의 단위이며, 스레드는 프로세스 안에서 실행되는 독립적인 기능 단위 하나하나를 의미합니다.
    
#### ⭐⭐ multi process와 multi thread를 비교설명해 주세요.

- 멀티스레드는 멀티 프로세스에 비해 스레드간 한 프로세스 내에서 메모리를 공유하기 때문에 차지하는 메모리 공간이 적고, 캐시 메모리를 초기화할 필요가 없어 Context Switching이 빠릅니다.
- 이에 비해 멀티프로세스는 멀티스레드보다 메모리를 많이 차지하며, Context Switching 시 많은 시간이 걸립니다.
- 멀티 스레드는 **동기화 문제**와 **메모리 공유로 인해 한 스레드 장애가 전체 스레드에 영향을 준다는 단점**이 있지만, 멀티 프로세스는 한 프로세스에 장애가 걸려도 전체 프로세스에 영향을 주지 않아 안정성이 높다는 장점이 있습니다.
    
#### multi thread가 multi process보다 좋은 점은 무엇인가요?

- 멀티스레드는 멀티 프로세스에 비해 메모리 공간이 많이 차지하지 않으며, Context Switching시 캐시 메모리를 초기화할 필요가 없어 속도가 빠릅니다.
- 또한 프로세스에 비해 자원을 할당하는 수가 적으므로 (스택만 할당받고 나머지는 공유) 자원을 효율적으로 관리할 수 있습니다.
- 데이터를 주고받을 때, 프로세스간의 통신인 IPC보다 멀티 스레드 간의 통신 비용이 적기때문에 통신으로 인한 오버헤드가 적습니다.
    
#### multi thread가 multi process보다 안좋은 점은 무엇인가요?

- 스레드 간의 자원공유로 인해 여러 스레드가 동일한 자원에 동시에 접근함으로 인해 발생하는 **동기화 문제**를 유의해서 프로그램 설계를 할 필요가 있으며, 한 스레드에 장애 발생 시 다른 스레드에도 영향이 간다는 점에서 안정성 이슈가 있습니다.
    
- Q. ⭐⭐ multi process환경에서 process간에 데이터를 어떻게 주고 받을까요?
    
    원칙적으로는 프로세스는 각각의 독자적인 주소 공간을 가지기 때문에, 다른 프로세스의 주소 공간을 참조할 수 없습니다. 하지만 경우에 따라 프로세스 간 데이터를 주고받을 수 있는 방법을 제공하는데, 이 매커니즘을 IPC 라고 합니다. IPC의 방식으로는 대표적으로 **공유 메모리 방식**과 **메시지 전달 방식**이 있습니다.
    
- Q. IPC의 예시를 들어주실 수 있나요?
    
    IPC는 공유 메모리와 메시지 전달 방식으로 나뉩니다. 공유 메모리 방식은 프로세스들이 주소 공간의 일부를 **공유**함으로써 이를 read & write하면서 통신하는 방식입니다. 메시지 전달 방식은 각 프로세스가 커널로부터 send/receive 연산을 제공받고, 이 연산을 통해 메시지를 커널에 시스템 콜을 하여 전달함으로써 통신하는 방식입니다.
    
- Q. 공유메모리와 메시지 전달 모델의 장단점을 설명해 주세요.
    
    공유 메모리는 초기에 kernel에 의한 공유 메모리 할당을 제외하면, 이후에는 kernel의 관여 없이 통신하기 때문에 속도가 빠릅니다. 하지만 프로세스 간 동시에 메모리 공간에 접근하면서 일관성 문제가 발생할 수 있으므로, 프로세스끼리 공유 메모리 접근에 대한 **동기화 문제를 책임**져야 한다는 단점이 있습니다.
    
    메시지 전달 모델은 kernel을 거쳐서 메시지를 주고받기 때문에 통신 속도가 느리다는 단점이 있습니다. 대신에 충돌을 회피할 필요가 없기 때문에 안정적이라는 장점이 있습니다.
    
### Thread-Safe하다는 것은 어떤 의미인가요?
    
- 멀티스레드 환경에서 여러 스레드가 같은 메모리에 접근을 시도하더라도 문제가 없이 작업이 진행되는 상황을 의미
    
#### Race-Condition이 무엇인가요?
    
- 멀티스레드 환경에서, 같은 시점에 여러 개의 스레드에서 하나의 메모리에 동시에 접근하고자 할 때 먼저 메모리를 사용하려는 경쟁 상황을 의미합니다.
    
#### ⭐ Multi process/thread 환경에서 동기화 문제를 어떻게 해결하나요? (=Thread-Safe를 보장하는 방법)
    
- 동기화 문제를 해결하기 위한 방식으로 대표적으로 mutex, semaphore가 있습니다.
- **Mutex**란, 공유 자원에 스레드 1개만이 접근할 수 있도록 하여 경쟁상황을 방지하는 기법입니다. 공유 자원을 점유하는 스레드가 lock을 걸면, 다른 스레드는 unlock이 될 때까지 기다려야합니다.
- **Semaphore**란, S개의 thread만이 공유 자원에 접근할 수 있도록 제어하는 동기화기법입니다.
우선 S라는 세마포 값을 가용한 자원의 수로 초기화를 한 다음, 자원에 접근 시 S— 연산, 방출 할 때는 S++ 연산을 수행하여 세마포 값을 증가시킵니다. 0인 경우에는 가용한 모든 자원이 사용중임을 의미하며, 이후 자원을 사용하고자 시도하는 프로세스는 세마포 값이 0보다 커지기 전까지 자원을 사용할 수 없습니다. 
    
#### mutex와 semaphore 기법을 비교 설명해 주세요.
    
- mutex는 오직 1개의 프로세스/스레드만이 공유 자원에 접근할 수 있고, Semaphore는 세마포 변수 크기만큼만 공유자원에 접근할 수 있습니다.
    
#### 교착상태(Deadlock)에 대해서 간단히 설명해 주세요.
    
- **둘 이상의 스레드**가 이미 다른 스레드가 점유하고 있는 자원을 **서로 기다릴 때 무한대기**에 빠지는 상황을 의미합니다.
    
- Q. deadlock은 언제 발생하게 되나요?
    
    데드락이 발생하는 조건으로는 4가지가 있는데, **상호 배제/점유 대기/비선점/순환 대기**입니다. 이 4가지 조건이 동시에 성립할 때 발생할 수 있습니다.
    
    상호 배제란 한 스레드만 자원을 점유할 수 있는 상황이고, 점유 대기는 스레드가 자원을 보유한 상황에서 다른 스레드가 자원을 추가로 기다리는 상황입니다.
    
    비선점은 다른 스레드가 사용 중인 자원을 강제로 선점할 수 없는 상황이고, 순환 대기는 대기 중인 스레드들이 순환 형태로 자원을 대기하고 있는 상황입니다.   
    
- Q. deadlock은 어떻게 해결할 수 있을까요?
    
    **무시, 예방, 회피, 탐지-회복**의 4가지 방법이 있습니다.
    
    무시하는 방법은 아무런 조치를 취하지 않고 데드락을 무시하는 방법으로, 현대 시스템에서는 데드락이 잘 발생하지 않고 해결 비용이 크기때문에 가장 많이 사용되는 방법입니다.
    
    예방은 교착 상태의 4가지 발생 조건 중 하나가 성립하지 않게 하는 방법입니다.
    
    회피는 스레드가 순환 대기 상태가 발생하지 않도록 자원을 할당하여 데드락을 회피하는 방법입니다.
    
    탐지-회복은 시스템 검사를 통해 데드락 발생을 탐지하여 이를 회복시키는 방법입니다.
    
#### 동기와 비동기, 블로킹과 논블로킹 차이에 대해 설명해주세요.
    
- 동기는 한 스레드에서 작업이 끝날때까지 다른 스레드가 작업할 수 없는 것을 의미하고, 비동기는 작업이 끝날때까지 기다리지 않고 다음 작업을 수행하는 것을 의미합니다.
- 블로킹은 CPU가 제어권을 바로 반환하지 않아 다른 스레드가 일을 하지 못해서 대기하는 상황을 의미합니다. 논블로킹은 CPU가 제어권을 호출했다가 바로 반환하는 방식으로, 한 스레드가 작업을 처리하더라도 다른 스레드도 CPU 제어권을 받아서 별도로 작업할 수 있는 상황을 의미합니다.
    
- Q. paging이란 뭔가요?
    
    페이징이란, 프로세스 주소 공간을 동일한 크기의 페이지 단위로 나누어 물리적 메모리의 서로 다른 위치에 페이지들을 저장하는 메모리 관리 방식입니다.
    
- Q. paging 기법 사용시 발생할 수 있는 **메모리 단편화(Memory fragmentation)** 문제에 대해 설명하시오
    
    메모리 단편화란, 메모리가 충분히 존재함에도 할당이 불가능한 상태를 의미합니다.
    
    외부 단편화와 내부 단편화가 있는데, 외부 단편화는 프로그램 크기가 물리적 메모리 공간보다 커서 할당할 수 없는 상태를 의미하는데 페이징 기법은 동일한 크기의 페이지 단위로 나누어서 할당하기 때문에 외부 단편화 문제가 발생하지는 않습니다.
    
    내부 단편화는 프로그램 크기보다 메모리 크기가 더 커서 낭비되는 메모리 공간이 있는 상황을 의미합니다. 페이징 기법은 프로세스 공간의 크기가 항상 페이지 단위의 배수라는 보장이 없으므로, 내부 단편화가 발생할 가능성은 있습니다.
    
- Q. segmentation에 대해서 설명해 주세요.
    
    세그멘테이션이란 프로세스의 메모리 공간을 논리적 의미 단위로 나누어서, 연속되지 않은 메모리 공간에 할당할 수 있도록 하는 메모리 관리 기법입니다.
    
- Q. segmentation의 **메모리 단편화(Memory fragmentation)** 문제에 대해 설명해 주세요.
    
    세그멘테이션은 논리적으로 필요한 크기만큼 메모리를 할당하므로 내부 단편화 문제가 발생하지 않습니다. 하지만 서로 다른 크기의 세그멘트들이 메모리에 적재되었다가 제거되는 일이 반복되면, 외부 단편화 문제가 발생할 가능성이 있습니다.
    
- Q. paging과 segmentation의 차이는 뭔가요?
    - 페이징기법은 프로세스의 메모리 공간을 같은 크기의 페이지 단위로 나누어 할당하는 것이고, 세그멘테이션은 의미 단위의 세그멘테이션으로 나누어 할당하는 기법이라는 점에서 차이가 있습니다.
    - **페이징 기법은 내부단편화 문제가 발생할 수 있는 데 반해 세그멘테이션 기법은 외부단편화 문제가 발생할 수 있습니다.**
- Q. paged segmentation 기법에 대해 설명하시오
    - 페이지드 세그멘테이션은 페이징 기법과 세그멘테이션 기법의 각 장점만을 취하는 메모리 관리 기법입니다. 의미 단위의 세그멘트로 나누되, 이 세그멘트들은 반드시 같은 크기의 페이지 단위로 나뉘어야합니다.
    - 외부단편화 문제를 해결하며, 기존 페이징 기법의 단점이었던 페이지 내의 프로세스 영역간 접근 권한 보호 조치를 해결해주는 기법입니다.
- Q. ⭐ 가상 메모리에 대해서 설명해 주세요.
    
    실제 메모리 개념과 개발자 입장의 논리 메모리 개념을 분리한 것입니다. 개발자가 메모리 크기를 염려할 필요가 없이 쉽게 프로그램을 작성할 수 있도록 하는 개념입니다.
    
- Q. 요구페이징(demand paging)이란 무엇인가요?
    
    **당장 사용될 주소 공간**을 페이지 단위로 메모리에 적재하는 방법을 요구 페이징이라고 합니다. 요구 페이징 기법에는 유효/무효 비트를 두어 각 페이지가 메모리에 존재하는지 확인하면서, 유효 비트에 해당하는 메모리만을 적재하게 됩니다.
    
- Q. 페이지 교체 알고리즘(replacement algorithm)을 아는대로 말씀해주세요.
    
    CPU가 무효 비트인 페이지에 접근하고자 하는 상황인 페이지 부재가 발생했을 때, 메모리에 올라와있는 페이지를 swap 영역인 디스크에 옮겨서 메모리 공간을 확보해야합니다. 이 때 어떤 페이지를 디스크에 옮겨서 페이지를 교체할 것인지 결정하는 알고리즘이 페이지 교체 알고리즘입니다.
    
- Q. LRU알고리즘과 LFU 알고리즘을 비교 설명해 주세요.
    
    LRU 알고리즘은 가장 오랫동안 사용되지 않은 페이지를 교체하는 방법이고, LFU 알고리즘은 참조 횟수가 가장 적은 페이지를 교체하는 방법입니다.
